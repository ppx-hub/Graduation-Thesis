%-------------------------------------------------------------------------------
%                参考文献
%-------------------------------------------------------------------------------

@article{2015Fast,
  author={Diehl, Peter U. and Neil, Daniel and Binas, Jonathan and Cook, Matthew and Liu, Shih-Chii and Pfeiffer, Michael},
  journal={2015 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing}, 
  year={2015},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/IJCNN.2015.7280696}}

@article{2016SSD,
  title={SSD: Single Shot MultiBox Detector},
  author={ Liu, W.  and  Anguelov, D.  and  Erhan, D.  and  Szegedy, C.  and  Reed, S.  and  Fu, C. Y.  and  Berg, A. C. },
  journal={Springer, Cham},
  year={2016},
}

@ARTICLE{2017Conversion,
  
AUTHOR={Rueckauer, Bodo and Lungu, Iulia-Alexandra and Hu, Yuhuang and Pfeiffer, Michael and Liu, Shih-Chii},   
	 
TITLE={Conversion of Continuous-Valued Deep Networks to Efficient Event-Driven Networks for Image Classification},      
	
JOURNAL={Frontiers in Neuroscience},      
	
VOLUME={11},      

PAGES={682},     
	
YEAR={2017},      
	
DOI={10.3389/fnins.2017.00682},      
	
ISSN={1662-453X},   
   
ABSTRACT={Spiking neural networks (SNNs) can potentially offer an efficient way of doing inference because the neurons in the networks are sparsely activated and computations are event-driven. Previous work showed that simple continuous-valued deep Convolutional Neural Networks (CNNs) can be converted into accurate spiking equivalents. These networks did not include certain common operations such as max-pooling, softmax, batch-normalization and Inception-modules. This paper presents spiking equivalents of these operations therefore allowing conversion of nearly arbitrary CNN architectures. We show conversion of popular CNN architectures, including VGG-16 and Inception-v3, into SNNs that produce the best results reported to date on MNIST, CIFAR-10 and the challenging ImageNet dataset. SNNs can trade off classification error rate against the number of available operations whereas deep continuous-valued neural networks require a fixed number of operations to achieve their classification error rate. From the examples of LeNet for MNIST and BinaryNet for CIFAR-10, we show that with an increase in error rate of a few percentage points, the SNNs can achieve more than 2x reductions in operations compared to the original CNNs. This highlights the potential of SNNs in particular when deployed on power-efficient neuromorphic spiking neuron chips, for use in embedded applications.}
}

@article{Spiking-yolo,
  title={Spiking-YOLO: Spiking Neural Network for Energy-Efficient Object Detection},
  author={ Kim, S.  and  Park, S.  and  Na, B.  and  Yoon, S. },
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={7},
  pages={11270-11277},
  year={2020},
}

@article{2020基于卷积神经网络的目标检测综述,
  title={基于卷积神经网络的目标检测综述},
  author={李同、阮士峰、陈卓、毛珍珍},
  journal={科技经济导刊},
  volume={v.28;No.725},
  number={27},
  pages={24-26},
  year={2020},
}

@article{2021脉冲神经网络研究进展综述,
  title = {脉冲神经网络研究进展综述},  
  author = {胡一凡、李国齐、吴郁杰、邓磊},
  journal = {控制与决策},
  volume = {36},
  number = {1},
  pages = {1},
  year = {2021},
  doi = {10.13195/j.kzyjc.2020.1006},
}

@article{2019Towards,
  title={Towards artificial general intelligence with hybrid Tianjic chip architecture},
  author={ Pei, J.  and  Deng, L.  and  Song, S.  and  Zhao, M.  and  Shi, L. },
  journal={Nature},
  volume={572},
  number={7767},
  pages={106},
  year={2019},
}

@article{2015脉冲神经网络的监督学习算法研究综述,
  title={脉冲神经网络的监督学习算法研究综述},
  author={蔺想红 and 王向文 and 张宁 and 马慧芳},
  journal={电子学报},
  number={03},
  pages={577-586},
  year={2015},
}
@INPROCEEDINGS{R-CNN,
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation}, 
  year={2014},
  volume={},
  number={},
  pages={580-587},
  doi={10.1109/CVPR.2014.81}}

  @INPROCEEDINGS{FastR-CNN,
  author={Girshick, Ross},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Fast R-CNN}, 
  year={2015},
  volume={},
  number={},
  pages={1440-1448},
  doi={10.1109/ICCV.2015.169}}

  @ARTICLE{FasterR-CNN,
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}, 
  year={2017},
  volume={39},
  number={6},
  pages={1137-1149},
  doi={10.1109/TPAMI.2016.2577031}}

  @ARTICLE{2013Conversion,
  author={Pérez-Carrasco, José Antonio and Zhao, Bo and Serrano, Carmen and Acha, Begoña and Serrano-Gotarredona, Teresa and Chen, Shouchun and Linares-Barranco, Bernabé},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Mapping from Frame-Driven to Frame-Free Event-Driven Vision Systems by Low-Rate Rate Coding and Coincidence Processing--Application to Feedforward ConvNets}, 
  year={2013},
  volume={35},
  number={11},
  pages={2706-2719},
  doi={10.1109/TPAMI.2013.71}}

  @ARTICLE{Lecun,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  doi={10.1109/5.726791}}

  @unknown{2016Hun,
author = {Hunsberger, Eric and Eliasmith, Chris},
year = {2016},
month = {11},
pages = {},
title = {Training Spiking Deep Networks for Neuromorphic Hardware},
doi = {10.13140/RG.2.2.10967.06566}
}

@misc{zambrano2016fast,
      title={Fast and Efficient Asynchronous Neural Computation with Adapting Spiking Neural Networks}, 
      author={Davide Zambrano and Sander M. Bohte},
      year={2016},
      eprint={1609.02053},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@article{Esser_2016,
   title={Convolutional networks for fast, energy-efficient neuromorphic computing},
   volume={113},
   ISSN={1091-6490},
   url={http://dx.doi.org/10.1073/pnas.1604850113},
   DOI={10.1073/pnas.1604850113},
   number={41},
   journal={Proceedings of the National Academy of Sciences},
   publisher={Proceedings of the National Academy of Sciences},
   author={Esser, Steven K. and Merolla, Paul A. and Arthur, John V. and Cassidy, Andrew S. and Appuswamy, Rathinakumar and Andreopoulos, Alexander and Berg, David J. and McKinstry, Jeffrey L. and Melano, Timothy and Barch, Davis R. and et al.},
   year={2016},
   month={Sep},
   pages={11441–11446}
}

@INPROCEEDINGS{YOLO,
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={You Only Look Once: Unified, Real-Time Object Detection}, 
  year={2016},
  volume={},
  number={},
  pages={779-788},
  doi={10.1109/CVPR.2016.91}}

  @article{Cao2014SpikingDC,
  title={Spiking Deep Convolutional Neural Networks for Energy-Efficient Object Recognition},
  author={Yongqiang Cao and Y. Chen and D. Khosla},
  journal={International Journal of Computer Vision},
  year={2014},
  volume={113},
  pages={54-66}
}

@misc{rueckauer2016theory,
      title={Theory and Tools for the Conversion of Analog to Spiking Convolutional Neural Networks}, 
      author={Bodo Rueckauer and Iulia-Alexandra Lungu and Yuhuang Hu and Michael Pfeiffer},
      year={2016},
      eprint={1612.04052},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@TECHREPORT{Krizhevsky09learningmultiple,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}
@INPROCEEDINGS{8594067,
  author={J. {Cartucho} and R. {Ventura} and M. {Veloso}},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Robust Object Recognition Through Symbiotic Deep Learning In Mobile Robots}, 
  year={2018},
  pages={2336-2341},
}
